{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "We start by importing everything we will be using to make the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from torchvision import transforms, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the imagenet class list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-02 19:35:01--  https://raw.githubusercontent.com/Lasagne/Recipes/master/examples/resnet50/imagenet_classes.txt?fbclid=IwAR19mHA3rPwm_4OynZs_G4oUG9qVhK33aMM7Z2ASLxNUChPp4LE6-V0GQ9Q\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.124.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.124.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 21674 (21K) [text/plain]\n",
      "Saving to: ‘imagenet_classes.txt’\n",
      "\n",
      "imagenet_classes.tx 100%[===================>]  21.17K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2020-04-02 19:35:01 (1.11 MB/s) - ‘imagenet_classes.txt’ saved [21674/21674]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O imagenet_classes.txt https://raw.githubusercontent.com/Lasagne/Recipes/master/examples/resnet50/imagenet_classes.txt?fbclid=IwAR19mHA3rPwm_4OynZs_G4oUG9qVhK33aMM7Z2ASLxNUChPp4LE6-V0GQ9Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the classes\n",
    "\n",
    "Start by loading the classes from the file. I output the top 5 of them just for confirmation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tench, Tinca tinca', 'goldfish, Carassius auratus', 'great white shark, white shark, man-eater, man-eating shark, Carcharodon carcharias', 'tiger shark, Galeocerdo cuvieri', 'hammerhead, hammerhead shark']\n"
     ]
    }
   ],
   "source": [
    "with open('imagenet_classes.txt') as f: #read the categories from file\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "print(classes[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Image\n",
    "\n",
    "We load the image using PIL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('./WelshCorgi.jpeg') #load image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to define a helper function for transforming images into the proper dimensions for AlexNet. We also want to transform the image into a tensor and then create a \"batch\" from our image (Add another dimension to the image). The final step is to normalize the image data to the means and standard deviation from the imagenet database. Otherwise the results wouldn't be very useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256), #change image dims to 256\n",
    "        transforms.CenterCrop(224), #crop the data to 224x224\n",
    "        transforms.ToTensor(), #convert to tensor\n",
    "        transforms.Normalize( #normalize data with imagenet mean and std dev\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "    img_n = transform(image) #apply the transform\n",
    "    return torch.unsqueeze(img_n, 0) #add one dimension to the start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to apply these changes to the image we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocess(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading AlexNet (rand init)\n",
    "\n",
    "First we load the image and the AlexNet not trained on any data. The weights will be initialized to random values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_net = models.alexnet() #random weights\n",
    "alex_net.eval() #set to evaluation mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets output the number of input and output features of the last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last layer has 4096000 input features and 1000 output features\n"
     ]
    }
   ],
   "source": [
    "params = [y.numel() for y in alex_net.parameters()]\n",
    "print(\"Last layer has\", params[-2], \"input features and\", params[-1], \"output features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to get a prediction from the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pred = alex_net(data) #get a prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a qucik function to summarize the top 5 predictions and print them out for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(out): #helper util to summarize the top 5 predictions\n",
    "    indices = torch.argsort(out, dim=1, descending=True)\n",
    "    prob = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
    "    top = [(classes[index], prob[index].item()) for index in indices[0][:5]]\n",
    "    for val in top:\n",
    "        print(\"Prediction:\",val[0], \"Probability\",val[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what is our picture?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: basset, basset hound Probability 0.10284849256277084\n",
      "Prediction: guacamole Probability 0.10280108451843262\n",
      "Prediction: airship, dirigible Probability 0.10280008614063263\n",
      "Prediction: wire-haired fox terrier Probability 0.10279516875743866\n",
      "Prediction: theater curtain, theatre curtain Probability 0.10271072387695312\n"
     ]
    }
   ],
   "source": [
    "summarize(image_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained AlexNet\n",
    "\n",
    "We'll continue using the above functions for a CNN pretrained on imagenet data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = models.alexnet(pretrained=True) #load pre trained data\n",
    "net.eval() #set to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pred2 = net(data) #get a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Pembroke, Pembroke Welsh corgi Probability 89.18708801269531\n",
      "Prediction: Cardigan, Cardigan Welsh corgi Probability 10.649338722229004\n",
      "Prediction: kelpie Probability 0.04727327823638916\n",
      "Prediction: Eskimo dog, husky Probability 0.04288318008184433\n",
      "Prediction: Shetland sheepdog, Shetland sheep dog, Shetland Probability 0.017419634386897087\n"
     ]
    }
   ],
   "source": [
    "summarize(image_pred2) #get summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are much better predictions!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
